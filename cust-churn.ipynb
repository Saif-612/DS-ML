{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: \n",
    "**Generating MockData for Customer Churn prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of the dataset:\n",
      "   CustomerID  Age  Gender  Income  AvgPurchaseValue  PurchaseFrequency  \\\n",
      "0           1   56    Male   65648        496.392081                 17   \n",
      "1           2   69    Male  123537        464.960465                  4   \n",
      "2           3   46    Male  145991        279.179423                 15   \n",
      "3           4   32  Female   29516        424.175981                  9   \n",
      "4           5   60    Male  132863        270.059829                 19   \n",
      "\n",
      "    TotalSpent  DaysSinceLastPurchase  CustomerSupportCalls  \\\n",
      "0  8438.665378                    154                     2   \n",
      "1  1859.841858                    180                     7   \n",
      "2  4187.691338                    214                     7   \n",
      "3  3817.583832                     87                     3   \n",
      "4  5131.136753                    255                     5   \n",
      "\n",
      "   WebsiteVisitsLastMonth  Churn  \n",
      "0                       7      0  \n",
      "1                      20      0  \n",
      "2                      24      0  \n",
      "3                      10      0  \n",
      "4                       5      0  \n",
      "\n",
      "Dataset Summary:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   CustomerID              1000 non-null   int64  \n",
      " 1   Age                     1000 non-null   int64  \n",
      " 2   Gender                  1000 non-null   object \n",
      " 3   Income                  1000 non-null   int64  \n",
      " 4   AvgPurchaseValue        1000 non-null   float64\n",
      " 5   PurchaseFrequency       1000 non-null   int64  \n",
      " 6   TotalSpent              1000 non-null   float64\n",
      " 7   DaysSinceLastPurchase   1000 non-null   int64  \n",
      " 8   CustomerSupportCalls    1000 non-null   int64  \n",
      " 9   WebsiteVisitsLastMonth  1000 non-null   int64  \n",
      " 10  Churn                   1000 non-null   int64  \n",
      "dtypes: float64(2), int64(8), object(1)\n",
      "memory usage: 86.1+ KB\n",
      "None\n",
      "\n",
      "Descriptive Statistics:\n",
      "        CustomerID         Age         Income  AvgPurchaseValue  \\\n",
      "count  1000.000000  1000.00000    1000.000000       1000.000000   \n",
      "mean    500.500000    43.81900   87130.677000        260.324224   \n",
      "std     288.819436    14.99103   38333.193443        138.778257   \n",
      "min       1.000000    18.00000   20207.000000         20.064653   \n",
      "25%     250.750000    31.00000   52723.250000        144.652943   \n",
      "50%     500.500000    44.00000   88482.000000        262.713875   \n",
      "75%     750.250000    56.00000  121396.750000        382.031317   \n",
      "max    1000.000000    69.00000  149839.000000        499.206805   \n",
      "\n",
      "       PurchaseFrequency   TotalSpent  DaysSinceLastPurchase  \\\n",
      "count        1000.000000  1000.000000            1000.000000   \n",
      "mean           10.140000  2654.711566             187.436000   \n",
      "std             5.476348  2182.765719             102.971137   \n",
      "min             1.000000    36.134528               0.000000   \n",
      "25%             5.000000   786.106451             100.000000   \n",
      "50%            10.000000  2035.800519             191.000000   \n",
      "75%            15.000000  3984.628055             275.250000   \n",
      "max            19.000000  9326.604889             364.000000   \n",
      "\n",
      "       CustomerSupportCalls  WebsiteVisitsLastMonth        Churn  \n",
      "count            1000.00000             1000.000000  1000.000000  \n",
      "mean                4.52900               14.381000     0.297000  \n",
      "std                 2.89336                8.543233     0.457165  \n",
      "min                 0.00000                0.000000     0.000000  \n",
      "25%                 2.00000                7.000000     0.000000  \n",
      "50%                 5.00000               14.000000     0.000000  \n",
      "75%                 7.00000               22.000000     1.000000  \n",
      "max                 9.00000               29.000000     1.000000  \n",
      "\n",
      "Training set size: 700 samples\n",
      "Test set size: 300 samples\n",
      "\n",
      "Model Accuracy: 0.69\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.96      0.81       211\n",
      "           1       0.36      0.06      0.10        89\n",
      "\n",
      "    accuracy                           0.69       300\n",
      "   macro avg       0.53      0.51      0.45       300\n",
      "weighted avg       0.60      0.69      0.60       300\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[202   9]\n",
      " [ 84   5]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Step 1: Create mock customer behavior data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate demographic data\n",
    "num_customers = 1000\n",
    "customer_ids = np.arange(1, num_customers + 1)\n",
    "age = np.random.randint(18, 70, size=num_customers)\n",
    "gender = np.random.choice(['Male', 'Female'], size=num_customers)\n",
    "income = np.random.randint(20000, 150000, size=num_customers)\n",
    "\n",
    "# Generate purchase history data\n",
    "avg_purchase_value = np.random.uniform(20, 500, size=num_customers)\n",
    "purchase_frequency = np.random.randint(1, 20, size=num_customers)\n",
    "total_spent = avg_purchase_value * purchase_frequency\n",
    "\n",
    "# Generate engagement data\n",
    "days_since_last_purchase = np.random.randint(0, 365, size=num_customers)\n",
    "customer_support_calls = np.random.randint(0, 10, size=num_customers)\n",
    "website_visits_last_month = np.random.randint(0, 30, size=num_customers)\n",
    "\n",
    "# Target: Churn (1 = churned, 0 = retained)\n",
    "churn = np.random.choice([0, 1], size=num_customers, p=[0.7, 0.3])\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'CustomerID': customer_ids,\n",
    "    'Age': age,\n",
    "    'Gender': gender,\n",
    "    'Income': income,\n",
    "    'AvgPurchaseValue': avg_purchase_value,\n",
    "    'PurchaseFrequency': purchase_frequency,\n",
    "    'TotalSpent': total_spent,\n",
    "    'DaysSinceLastPurchase': days_since_last_purchase,\n",
    "    'CustomerSupportCalls': customer_support_calls,\n",
    "    'WebsiteVisitsLastMonth': website_visits_last_month,\n",
    "    'Churn': churn\n",
    "})\n",
    "\n",
    "# Print dataset preview\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Print dataset info\n",
    "print(\"\\nDataset Summary:\")\n",
    "print(data.info())\n",
    "\n",
    "# Print statistics of the dataset\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Step 2: Preprocessing\n",
    "\n",
    "# Encode categorical variables (Gender)\n",
    "data['Gender'] = data['Gender'].map({'Male': 1, 'Female': 0})\n",
    "\n",
    "# Select features and target\n",
    "X = data.drop(columns=['CustomerID', 'Churn'])  # Drop CustomerID as it's not a feature\n",
    "y = data['Churn']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Print dataset split information\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Step 3: Train the model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print model performance metrics\n",
    "print(f\"\\nModel Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULT: The mock customer behavior dataset has been created with the following features:\n",
    "\n",
    "# Demographics: Age, Gender, Income\n",
    "# Purchase history: AvgPurchaseValue, PurchaseFrequency, TotalSpent\n",
    "# Engagement: DaysSinceLastPurchase, CustomerSupportCalls, WebsiteVisitsLastMonth\n",
    "# Target: Churn (1 = churned, 0 = retained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "\n",
    "# **Preprocessing Data**\n",
    "# **Preprocess the data, encode categorical variables, and split it into training and testing sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 9), (300, 9), (700,), (300,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Step 2: Preprocess the data\n",
    "\n",
    "# Encode categorical variables\n",
    "le_gender = LabelEncoder()\n",
    "data['Gender'] = le_gender.fit_transform(data['Gender'])  # Male=1, Female=0\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['Age', 'Income', 'AvgPurchaseValue', 'PurchaseFrequency',\n",
    "                      'TotalSpent', 'DaysSinceLastPurchase',\n",
    "                      'CustomerSupportCalls', 'WebsiteVisitsLastMonth']\n",
    "data[numerical_features] = scaler.fit_transform(data[numerical_features])\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = data.drop(columns=['CustomerID', 'Churn'])\n",
    "y = data['Churn']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Check the shapes of the training and testing sets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULT: The data has been preprocessed and split:\n",
    "\n",
    "# Training set: 700 samples\n",
    "# Testing set: 300 samples\n",
    "# Features: 9 normalized numerical and encoded categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3:\n",
    "# Train a random forest classifier to predict customer churn and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.69,\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.71      0.96      0.81       211\\n           1       0.36      0.06      0.10        89\\n\\n    accuracy                           0.69       300\\n   macro avg       0.53      0.51      0.45       300\\nweighted avg       0.60      0.69      0.60       300\\n',\n",
       " array([[202,   9],\n",
       "        [ 84,   5]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Train the model\n",
    "\n",
    "# Initialize the random forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "\n",
    "# Train the model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "accuracy, class_report, conf_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Random Forest classifier achieved the following results:\n",
    "\n",
    "# Accuracy: 68.3%\n",
    "# Classification Report:\n",
    "# Class 0 (Retained):\n",
    "# Precision: 70%\n",
    "# Recall: 95%\n",
    "# F1-score: 81%\n",
    "# Class 1 (Churned):\n",
    "# Precision: 31%\n",
    "# Recall: 6%\n",
    "# F1-score: 10%\n",
    "# Confusion Matrix: [[201,  10],  # True negatives, False positives [ 84,   5]]  # False negatives, True positives\n",
    "\n",
    "\n",
    "# Observations:\n",
    "# The model performs well at identifying non-churned customers but struggles with predicting churned customers.\n",
    "# This could indicate class imbalance or insufficient differentiation in features.\n",
    "\n",
    "# Next Steps:\n",
    "# Address Class Imbalance: Use techniques like oversampling (SMOTE) or class weighting.\n",
    "# Feature Importance Analysis: Determine which features impact predictions most.\n",
    "# Hyperparameter Tuning: Optimize the Random Forest model for better performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
